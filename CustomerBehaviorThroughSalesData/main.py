# -*- coding: utf-8 -*-
"""[Completed] Understanding_Customer_Behavior_through_Sales_Data.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uPKJ95rg4CAgpwC1nl1W4bCw7uNNcAOn

# Understanding Customer Behavior through Sales Data

This project involves statistical analysis of the Supermarket Sales dataset to extract insights into customer behavior. Exploratory data analysis and K-Means clustering techniques are applied to identify distinct consumer segments, providing valuable information to support strategic business decisions.

The Supermarket Sales dataset includes the following key columns:

* *Invoice ID* – Unique identifier for each transaction.

* *Branch* – Store branch code (A, B, or C).

* *City* – City where the store is located (e.g., Yangon, Naypyitaw, Mandalay).

* *Customer type* – Type of customer: Member (loyalty program) or Normal (walk-in customer).

* *Gender* – Gender of the customer (Male or Female).

* *Product line* – Category of the product purchased (e.g., Health & Beauty, Food & Beverages, Electronic Accessories, etc.).

* *Unit price* – Price per unit of the product.

* *Quantity* – Number of items purchased in the transaction.

* *Tax 5%* – 5% tax applied to the total before tax.

* *Sales* – Total amount paid by the customer (includes tax).

* *Date* – Date when the transaction took place.

* *Time* – Time when the transaction occurred.

* *Payment* – Payment method used (e.g., Cash, Credit Card, Ewallet).

* *COGS* – Cost of Goods Sold; subtotal before tax (raw cost of the products)

* *Gross margin percentage* – Fixed margin percentage on COGS (in this dataset, it’s consistently 4.7619%).

* *Gross income* – Profit earned from the transaction.

* *Rating* – Customer satisfaction rating, ranging from 4 to 10.

---
"""

#Import library
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans
from sklearn.preprocessing import MinMaxScaler

from helper import assign_time_period, find_outliers

"""## Import dataset and pre-processing

**Import dataset**
"""

from google.colab import files
uploaded = files.upload()

df = pd.read_csv("SuperMarket Analysis.csv")

df.shape

df.columns

df.head()

"""**Null values and duplicate analysis**"""

print("Are there duplicate values? ", df.duplicated().any())
print("Are there null values? ", df.isnull().values.any())

"""**Features analysis**"""

print(df.dtypes)

# Find the unique values for each non-numeric column
for col in df.drop(columns = ['Invoice ID','Date','Time']).select_dtypes(include='object').columns:
    print(f"\nColumn: {col}")
    print(f"Unique values ({df[col].nunique()}): {df[col].unique()}")

"""▶ City and Branch have both 3 unique values. Check if the association is 1:1"""

print('Unique combinations: \n' , df[['Branch','City']].drop_duplicates())

"""One-to-one relationship between branch and city.

**Data time preprocessing**
"""

# Convert the 'Date' column to datetime format
df['Date'] = pd.to_datetime(df['Date'],  format = '%m/%d/%Y')

# Extract day name (e.g., Monday, Tuesday, etc.)
df['DayOfWeek'] = df['Date'].dt.day_name()

# Convert the 'Time' column to datetime format
df['Time'] = pd.to_datetime(df['Time'])

# Extract the hour
df['Hour'] = df['Time'].dt.hour

# Extract time of day
df['TimeOfDay'] = df['Hour'].apply(assign_time_period)

print(df.head())

"""## Descriptive analysis"""

# Analyze summary statistics for the numerical variables
df.describe()

"""▶ Initial Dataset Overview:

   



*   The dataset collects customer purchases made in **2019**, specifically during the period from **January 1st to March 30th**.

*   The preliminary analysis reveals that **Sales** exhibit high variability, primarily driven by fluctuations in Unit price.

*   Similarly, the **Cost of Goods Sold** (COGS) shows significant variability.


*   Both **Sales** and **COGS** are crucial in directly determining the Gross Income.






"""

#sns.kdeplot(df['Sales'], fill=True)
#sns.kdeplot(df['cogs'], fill=True)
sns.kdeplot(df['gross income'], fill=True)

"""▶ Key observations:

The distribution of **Gross Income** is **right-skewed**, indicating that most profits fall below the average, with only a few transactions generating very high profits.

**Quantitative variable distribution analysis**
"""

variables = ['Sales', 'cogs', 'gross income', 'Rating']

# Density plots in a 1x4 grid
plt.figure(figsize=(20,5))
for i, var in enumerate(variables, 1):
    plt.subplot(1, 4, i)
    sns.kdeplot(df[var], fill=True)
    plt.title(f'Density Plot of {var}')
    plt.xlabel(var)
    plt.ylabel('Density')
plt.tight_layout()
plt.show()

# Boxplots in a 1x4 grid
plt.figure(figsize=(20,5))
for i, var in enumerate(variables, 1):
    plt.subplot(1, 4, i)
    sns.boxplot(x=df[var])
    plt.title(f'Boxplot of {var}')
    plt.xlabel(var)
plt.tight_layout()
plt.show()

"""▶ Key Observations:



*   As anticipated, the distribution of **Gross Income** aligns with that of **Sales** and **Cost of Goods Sold** (COGS), reflecting their direct relationship. Furthermore, the boxplot analysis for these variables highlights the presence of several outliers.

*   In contrast, the **Rating** distribution exhibits a high degree of symmetry.

**Quantitative variable outliers analysis**
"""

# Extract the outliers

outliers_sales = find_outliers(df, 'Sales')
outliers_income = find_outliers(df, 'gross income')
print(f"Outliers for 'Sales':")
print(outliers_sales)
print(f"Number of outliers: {len(outliers_sales)}\n")
print(f"Outliers for 'gross income':")
print(outliers_income)
print(f"Number of outliers: {len(outliers_income)}\n")

# Sales and Gross Income have the same number of outliers. Check if they belong to the same observations.
print(outliers_sales.index == outliers_income.index)

"""▶ Key observations:

The outliers in Sales and Gross Income originate from the same observations. This outcome is expected, given that Gross Income is directly derived from the Sales amount.


"""

variables = ['DayOfWeek','Hour','Customer type','Gender','Payment','Product line']

print(outliers_sales.groupby(['City','TimeOfDay']).size().sort_values(ascending=False), '\n')
for var in variables:
  print(outliers_sales[var].value_counts(ascending=False), '\n')

"""▶ Key observations:



*   These high-value transactions occurred most frequently on **Wednesdays** and **Fridays**, primarily during the **afternoon**, with peaks observed in post-lunch hours.

*   Geographically, a significant portion originated from **Naypyitaw**.

*   Demographically, **female** customers accounted for the majority of these purchases.

*   Interestingly, most were made by **non-members**, highlighting a potential area of inefficiency within the loyalty program.

*   As for payment, the **credit card** was the most frequently used method, possibly due to its deferred payment capability.

*   Finally, the dominant product categories among these outlier purchases were **Home and Lifestyle** and **Fashion Accessories**.
"""

# Extract the Sales values in the quantiles 0.90 to 0.99

print('Lowest Sales outlier: ', outliers_sales['Sales'].min(), '\n')

for i in range(90, 100, 1):
  pct_i = df['Sales'].quantile(i/100)
  pct_prev = df['Sales'].quantile((i-1)/100)
  delta = round(pct_i - pct_prev, 2)
  print('Percentile', i)
  print('Sales:', round(df['Sales'].quantile(i/100), 2))
  print('Delta:', delta)

"""▶ Understanding the results:

The sales outliers, while representing the top 1% of transactions, aren't excessively far from the 99th percentile. Moreover, the increase in these most extreme percentiles remains quite stable, hovering around 20-30%. This suggests we can reasonably consider these transactions as realistic.

**Correlation Matrix**
"""

# Select only numerical columns from the DataFrame
numeric_df = df.select_dtypes(include=['number'])

# Calculate the correlation matrix for these numerical columns
correlation_matrix = numeric_df.corr()
#print(correlation_matrix)

# Create a heatmap to visualize the correlation matrix
plt.figure(figsize=(8,6))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Matrix of Quantitative Variables')
plt.show()

"""▶ Understanding the results:

*   Surprisingly, **Quantity and Price** show almost no correlation, which goes against the expected negative relationship. This suggests that customers' purchasing habits aren't significantly affected by price changes.

*   As anticipated, **Sales and COGS** are highly and positively correlated with both price and quantity, a natural outcome given their linear dependence on these variables.

*   Lastly, **Rating** doesn't exhibit any strong correlations that would offer useful insights.

## Frequency analysis
"""

df.columns

# Select only the categorical variables
categorical_var = df.drop(columns = 'Invoice ID').select_dtypes(include='object').columns

# Calculate the relative frequency
for var in categorical_var:
  freq_abs = df[var].value_counts(normalize = True)*100
  print(f'Relative frequency: {freq_abs} \n')

# Show the mode
print('Mode')
for var in categorical_var:
  print(f'{var}: {list(df[var].mode())}')

"""▶ Understanding the result:

*   **Balanced Sales Across Locations**: Sales activity is well distributed geographically, with branches and cities showing nearly equal representation.

*   **Loyalty Program Insights**: While most transactions are from loyalty program members, interestingly, most high-value (outlier) purchases are made by non-members. This suggests the loyalty program might not be effectively engaging or rewarding its top-spending customers.

*   **Demographics**: Female customers account for the majority of overall transactions, a trend consistent with their prevalence among outlier purchases.

*   **Product Preferences**: Sales are fairly even across product lines. Fashion Accessories lead slightly, a trend also observed in the outlier analysis.

*   **Time of Purchase**: Transactions are more frequent in the afternoon and evening, supporting the pattern found among outlier purchases.

*   **Payment Methods**: Payment preferences are quite balanced. E-wallets are slightly more common, while Credit Cards are the least used overall. This reinforces the idea that high-value customers might prefer credit cards for their flexibility or deferred payment options when making larger expenditures.

*   **Weekday Patterns**: Customer demand remains steady throughout the week with minor fluctuations. Monday is the least active day, and Saturday the most active, aligning with typical shopping behavior where people shop less at the start of the workweek and more on their days off.

## Data Exploration with Queries

**Analysis by single variable**
"""

var = ['City', 'Customer type', 'Gender', 'Product line', 'Payment', 'DayOfWeek', 'TimeOfDay']

for i in var:
  print(df.groupby(i)['Sales'].mean().sort_values(ascending=False),'\n')

"""▶ Understanding the result:

*   **Location Performance**: Naypyitaw stands out with the highest average sales per transaction, aligning with our earlier finding that it's a primary source of high-value outlier purchases.

*   **Loyalty Program Effectiveness**: While loyalty program members generally show a higher average sales value per transaction, the fact that most outlier purchases are made by non-members confirms the need to improve the loyalty program's effectiveness.

*   **Gender and Sales**: Female customers demonstrate significantly higher average sales per transaction compared to male customers, reinforcing previous observations.

*   **Product Line Profitability**: 'Home and lifestyle' and 'Sports and travel' product lines boast the highest average sales per transaction. This is consistent with 'Home and lifestyle' being a leading category among outliers. However, 'Fashion accessories' is surprisingly the least profitable category, which contradicts initial expectations from previous analyses.

*   **Payment Method Trends**: Cash and Credit card payments show slightly higher average sales per transaction. This aligns with earlier insights, suggesting high-value customers might favor credit cards for their flexibility. E-wallet, despite its overall prevalence, shows only a tiny difference in average sales compared to other payment methods.

*   **Weekday Sales Dynamics**: Saturdays exhibit the highest average sales per transaction, while Mondays have the lowest, mirroring typical shopping behavior. Interestingly, Wednesdays and Fridays, despite having lower overall average sales, were also the days with the most frequent outliers. This suggests that the average sales on these days are primarily driven by low-value customers.

*   **Time of Day Impact**: Transactions occurring in the afternoon show the highest average sales, which is consistent with previous findings.

**Analysis by multiple variables**
"""

print(
    df.pivot_table(
    values = 'Sales',
    index = 'City',
    columns = 'Customer type',
    aggfunc= ['sum','mean'],
    fill_value=0
  ),
    '\n')

print(
    df.pivot_table(
    values = 'Sales',
    index = 'Product line',
    columns = 'Gender',
    aggfunc= ['sum','mean'],
    fill_value=0
  ),
    '\n')

print(
    df.pivot_table(
    values = 'Sales',
    index = 'Payment',
    columns = 'Customer type',
    aggfunc= ['sum','mean'],
    fill_value=0
  ),
    '\n')

print(
    df.pivot_table(
    values = 'Sales',
    index = 'DayOfWeek',
    columns = 'TimeOfDay',
    aggfunc= ['sum','mean'],
    fill_value=0
  ),
    '\n')

"""▶ Understanding the result.

 '**Health and beauty**' stands out as the only product category where male customers contribute more to sales than female customers.

## Label Encoding
"""

cat_variables = ['City', 'Gender', 'Customer type', 'Product line', 'Payment']

# Convert the categorical variables into dummy format
df_encoded = pd.get_dummies(df, columns=cat_variables, drop_first=True)
df_encoded.head()

df_encoded.columns

# Convert DayOfWeek and TimeOfDay into numeric variables

DayOfWeek_mapping = {
    "Monday": 0,
    "Tuesday": 1,
    "Wednesday": 2,
    "Thursday": 3,
    "Friday": 4,
    "Saturday": 5,
    "Sunday": 6
}

TimeOfDay_mapping = {
    'Morning': 0,
    'Afternoon': 1,
    'Evening': 2
}

df_encoded['DayOfWeek_encoded'] = df_encoded['DayOfWeek'].map(DayOfWeek_mapping)
df_encoded['TimeOfDay_encoded'] = df_encoded['TimeOfDay'].map(TimeOfDay_mapping)

df_encoded[['DayOfWeek_encoded', 'TimeOfDay_encoded']].head()

"""## Clustering"""

# Define different variable combinations to cluster the customers

input1 = ['Sales', 'Quantity', 'Unit price', 'Customer type_Normal', 'Gender_Male', 'City_Naypyitaw', 'City_Yangon', 'Product line_Home and lifestyle']
input2 = ['Sales', 'Quantity', 'TimeOfDay_encoded', 'Customer type_Normal']
input3 = ['Sales', 'Quantity', 'Unit price', 'Customer type_Normal']
input4 = ['Sales', 'Quantity', 'Unit price', 'Payment_Credit card']
input5 = ['Sales', 'Quantity', 'Unit price', 'Gender_Male']
input6 = ['Sales', 'Quantity', 'Unit price']
all_inputs = [input1, input2, input3, input4, input5, input6]

# Iterate a loop over the inputs to cluster the transactions into Sales clusters. The goal is to identify 3 groups: high-values, mid-value, low-value.

plt.figure(figsize=(20, 10))
for i, input in enumerate(all_inputs, 1):

  # Select features for clustering
  customer_data = df_encoded[input]
  scaler = MinMaxScaler()
  customer_data_scaled = scaler.fit_transform(customer_data)

  # Apply K-Means
  kmeans = KMeans(n_clusters=3, random_state=42)
  df_encoded['Customer Segment'] = kmeans.fit_predict(customer_data_scaled)

  # Visualize Clusters
  plt.subplot(2, 3, i)
  sns.scatterplot(x = df_encoded['Sales'], y = df_encoded['Quantity'], hue=df_encoded['Customer Segment'], palette="Set1")
  plt.title(f'Customer Segmentation based on input{i}')
  plt.tight_layout
plt.show()

# Reiterate the clusterization to determine the mean of the variables across the customer segments

for i, input in enumerate(all_inputs, 1):

  # Select features for clustering
  customer_data = df_encoded[input]
  scaler = MinMaxScaler()
  customer_data_scaled = scaler.fit_transform(customer_data)

  # Apply K-Means
  kmeans = KMeans(n_clusters=3, random_state=42)
  df_encoded['Customer Segment'] = kmeans.fit_predict(customer_data_scaled)

  # Determine the mean values for all customer segments
  aggregated_clusters = df_encoded.groupby('Customer Segment')[input].mean().sort_values(by='Sales', ascending=False)
  aggregated_clusters.index = ['High-value', 'Mid-value', 'Low-value']
  aggregated_clusters.index.name = 'Customer segment'
  print(f'{i}) Cluster summary (mean values)')
  print(f'{round(aggregated_clusters,2)} \n')

"""▶ Understanding the result



*   This clusterization's segmentation is primarily driven by **City and Gender**, as sales factors (Sales, Quantity, Unit price) have little effect. Visually, the segments appear mixed and highly overlapping. The mean on the membership dummy differs from previous findings, showing that both moderate and low-value customers hold membership. Additionally, TimeOfDay_encoded and 'Home and lifestyle' product line do not provide useful segmentation information.

*   Here, **customer segments** are **clearly separated** into high, mid, and low-value groups based on Sales and Quantity. The membership loyalty program attracts both low-value and high-value customers, indicating a need for further performance analysis. The time of day remains irrelevant, being steady across clusters.

*   Resembling the first clusterization, this analysis includes Unit price. The clusters are well-separated, with **Unit price** positively contributing to their differentiation, as expected due to its correlation with Sales. This setup effectively uses membership to distinguish Mid-value customers from others.

*   Replacing the membership dummy with the credit card dummy yields similar broad results. **Credit card** usage concentrates among moderate spenders, while low and high spenders favor other payment methods. However, including this variable slightly reduces the clarity of the High-value group, with a smaller sales difference from the Mid-value cluster compared to the previous summary.

*   This summary replaces the credit card dummy with gender. The overall result is consistent, showing clear sales differences across segments. The analysis identifies **high-value and low-value** segments **among female buyers**, and a **moderate-value** segment **for male buyers**.

*   This final clusterization relies solely on purchasing metrics: Sales, Quantity, and Unit price. Sales are very different across segments, and an interesting insight is that moderate and high-spending customers buy a similar amount of items, with price being the main factor affecting their sales. Visually, the clusters are perfectly separated with almost no overlapping, due to the strong correlation between Sales with Quantity and Price. However, this combination limits intervention on more actionable variables like those mentioned previously.


**Overall conclusion**

By looking at the visualizations, the best combinations of variables for clear visual distinction arise from summaries 3), 4), and 5), as they successfully cluster sales into easily distinguishable segments. Ultimately, the optimal choice should be the combination that includes the membership loyalty (from Summary 3), as it most directly addresses the supermarket's strategic goals concerning its loyalty program and customer relationships.





"""